# CoNLL2003命名实体识别项目报告

## 前言

NER全称是命名实体识别（Named Entity Recognition, NER），目标是识别文本中感兴趣的实体，如位置、组织和时间。NER 是属于自然语言处理中的序列标注任务(sequence tagging)，序列标注中除了NER，还有如词性（POS）标记和分块（Chunking）等。已识别的实体可以在各种下游应用程序中使用，比如根据患者记录去识别和信息提取系统，也可以作为机器学习系统的特性，用于其他自然语言处理任务。NER总结的看其实就是提取出属于预定义类别的文本片段，它可能是通用性的，也可能是用户定义好的类型，属于特定的领域。

### 项目介绍

项目中的数据集使用的是CoNLL2003英文数据集，数据集包含训练集（14041个样本）、验证集（3250个样本）和测试集（3453个样本）。数据集中的目标实体分为人名（PER）、地名（LOC）、机构名（ORG），其他实体（MISC）。它使用标准的BIOUL实体标注方式，因此标注中包含 (B/L/U/I)-(PER/LOC/ORG/MISC) 这十六种标注以及 O 表示其他，共十七种标注类型。

项目的模型任务便是准确地识别出每一个实体以及它的类型，训练任务会在训练集和验证集上进行，通过验证集来优化模型参数，最后会在测试集上进行测试，计算Accuracy、Precision、Recall和F1等指标来评估模型。

通过调研NER的发展历程，我了解到NER的发展经历了从基于规则的线性模型，到后来的监督学习方法（HMM，DT，CRF等），再到近年来的深度学习方法的大流行。为了对比研究各类NER方法在CoNLL2003数据集上的效果，以及研究不同模型之间的异同和优劣，这里我们分别实现了传统的监督学习方法HMM和CRF来进行命名实体的识别，同时使用卷积神经网络、循环神经网络，以及预训练模型RoBERTa方法分别进行实体的识别。

在下一个部分的研究进展中，本文对NER方面的研究发展过程进行了简单的综述，方便理解命名实体识别领域的研究趋势；在实验模型介绍部分，我们针对各个模型的原理进行了简要的介绍和总结对比，希望能从模型原理上解释实验的结果差异；在实验结果部分，对各个模型的结果进行了总结和分析；最后，本文对命名实体识别项目做了一个简要的总结。

## 研究进展

xxxxx

近年来，使用大规模的语料数据进行模型的预训练，然后在下游任务进行任务和数据导向的微调，成为了自然语言处理领域各个任务的主流方法。最具代表性的是BERT，它的提出是从监督学习方法到无监督预训练模型的转折。随后各类方法大多都是在Transformer基础上，调整预训练任务和策略等。比较有名的有GPT系列，XLNET，ALBERT，RoBERTa等，它们的核心模块都是自注意力机制，通用特点是使用大规模语料训练大规模的语言模型，提取通用的语言特征。目前

## 实验模型介绍

模型（四个baseline）介绍框架embedding->encoder->tagger（系统主要模块流程），介绍baseline，再介绍自己的核心想法+伪代码

## 实验结果分析

## 总结

## 参考文献
