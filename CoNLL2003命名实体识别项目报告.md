# CoNLL2003命名实体识别项目报告

## 前言

NER全称是命名实体识别（Named Entity Recognition, NER），目标是识别文本中感兴趣的实体，如位置、组织和时间。NER 是属于自然语言处理中的序列标注任务(sequence tagging)，序列标注中除了NER，还有如词性（POS）标记和分块（Chunking）等。已识别的实体可以在各种下游应用程序中使用，比如根据患者记录去识别和信息提取系统，也可以作为机器学习系统的特性，用于其他自然语言处理任务。NER总结的看其实就是提取出属于预定义类别的文本片段，它可能是通用性的，也可能是用户定义好的类型，属于特定的领域。

### 项目介绍

项目中的数据集使用的是CoNLL2003英文数据集，数据集包含训练集（14041个样本）、验证集（3250个样本）和测试集（3453个样本）。数据集中的目标实体分为人名（PER）、地名（LOC）、机构名（ORG），其他实体（MISC）。它使用标准的BIOUL实体标注方式，因此标注中包含 (B/L/U/I)-(PER/LOC/ORG/MISC) 这十六种标注以及 O 表示其他，共十七种标注类型。

项目的模型任务便是准确地识别出每一个实体以及它的类型，训练任务会在训练集和验证集上进行，通过验证集来优化模型参数，最后会在测试集上进行测试，计算Accuracy、Precision、Recall和F1等指标来评估模型。

通过调研NER的发展历程，我了解到NER的发展经历了从基于规则的线性模型，到后来的监督学习方法（HMM，DT，CRF等），再到近年来的深度学习方法的大流行。为了对比研究各类NER方法在CoNLL2003数据集上的效果，以及研究不同模型之间的异同和优劣，这里我们分别实现了传统的监督学习方法HMM和CRF来进行命名实体的识别，同时使用卷积神经网络、循环神经网络，以及预训练模型RoBERTa方法分别进行实体的识别。

在下一个部分的研究进展中，本文对NER方面的研究发展过程进行了简单的综述，方便理解命名实体识别领域的研究趋势；在实验模型介绍部分，我们针对各个模型的原理进行了简要的介绍和总结对比，希望能从模型原理上解释实验的结果差异；在实验结果部分，对各个模型的结果进行了总结和分析；最后，本文对命名实体识别项目做了一个简要的总结。

## 研究进展

命名实体识别NER的任务目标是给出一个命名实体的起始和终止边界，并给出命名实体的类别。一般而言完成NER任务的方法分为基于规则、基于无监督方法、基于特征的机器学习方法和基于深度学习的方法四种。其中一般领域性比较强，数据量很少的NER任务会用规则，其余基本上都是机器学习或者深度学习。尤其是在数据量比较充足的时候，深度学习一般都可以获得比较不错的效果。

在基于规则的NER任务中，需要手工指定符合条件的词及其对应的类别。具体使用的规则包括特定领域词典、同义词典、句法词汇模板和正则表达式等等。其优点在于不需要进行数据标注，但是指定规则工作量大，需要不断维护，同时迁移成本较高，常用的NER系统包括LaSIE-II, NetOwl等。当词汇表足够大时，基于规则的方法能够取得不错效果。但总结规则模板花费大量时间，且词汇表规模小，且实体识别结果普遍高精度、低召回。基于无监督的NER学习方法中使用聚类的方法，根据文本相似度进行不同实体类别组的聚类，同样不需要标注数据，但得到的结果准确度有限。常用到的特征或者辅助信息有词汇资源、语料统计信息（TF-IDF）、浅层语义信息（分块NP-chunking）等。基于特征的有监督学习方法中，NER任务可以视为机器学习token 级别的多分类任务或序列标注任务， 需要标注数据，同时一般结合精心设计的特征，包括词级别特征、文档特征和语料特征等等。常用的NER机器学习模型包括隐马尔可夫模型 HMM、决策树 DT、最大熵模型 MEM、最大熵马尔科夫模型 HEMM、支持向量机 SVM、条件随机场 CRF等。

深度学习NER受益于DL非线性，相比于传统线性模型可以学到更为复杂并对模型有益的特征，端到端过程得以实现，近年来成为主流研究方向。近年来，使用大规模的语料数据进行模型的预训练，然后在下游任务进行任务和数据导向的微调，成为了自然语言处理领域各个任务的主流方法。得益于大规模的语料，以及自注意力机制的存在，预训练模型能够很好地学习语言本身具有的含义，并且通过无监督的训练方式得到一个具备潜在语义信息的编码，这种通用的包含语义的编码能够适应大部分下游任务，也具有更强的表示能力。最具代表性的是BERT，它的提出是从监督学习方法到无监督预训练模型的转折。随后各类方法大多都是在Transformer基础上，调整预训练任务和策略等。比较有名的有GPT系列，XLNET，ALBERT，RoBERTa等，它们的核心模块都是自注意力机制，通用特点是使用大规模语料训练大规模的语言模型，提取通用的语言特征。目前大多数方法都是基于深度学习模型训练得到文本的隐语义编码，然后通过结合CRF模型得到预测结果。这样充分结合了深度学习强大的编码能力和传统机器学习的分类能力，也避免了深度学习模型在预测命名实体类别时，出现不可控的情况，例如B-PER后面不可能出现B-PER，这是一种规则约束，而单纯的深度学习模型是有可能出现这种情况的，结合CRF，通过学习得到一系列规则约束，避免了这些问题。

除了模型方面，近年来的研究偏向于结合不同级别的语义编码，从字符级别，到词级别，到实体级别的编码，不同模型之间的区别可能就在于如何提取这些编码，以及如何后处理这些编码。LUKE模型便是在其基础上对实体级别的编码进行预训练，并且使用BERT语言模型的掩码机制和新的训练任务，结合实体级别的自注意力机制，最终在多个实体相关的任务上获得了SOTA效果。

目前在命名实体识别领域，实体识别效果最好的是使用ACE模型(Automated Concatenation of Embeddings)结合文档级上下文语义，模型的目标是找到更好的embedding拼接方式，并且使用神经网络结构搜索的方式来自动化寻找拼接方式这一过程，而不是人为定义好拼接哪些embeddding。同时论文中使用了强化学习方法对模型进行训练，对于好的拼接方式，模型将会得到一个奖励，反之会得到一个惩罚，这样一个强化学习的奖励机制能够让模型学习到具体应该拼接哪些embedding。

## 实验模型介绍

模型（四个baseline）介绍框架embedding->encoder->tagger（系统主要模块流程），介绍baseline，再介绍自己的核心想法+伪代码

### HMM

### CRF

### BiLSTM+CRF

### CNN+BiLSTM+CRF

### BERT+BiLSTM+CRF

### RoBERTa+BiLSTM+CRF

## 实验结果分析

## 总结

## 参考文献